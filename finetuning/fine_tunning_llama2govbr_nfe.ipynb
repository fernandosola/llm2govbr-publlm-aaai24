{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d16f921-cc45-4d70-8e39-6598f7ccf0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-02-24 17:25:15,584] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/data_share/venv202311_01/lib/python3.11/site-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "import datasets\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_columns = 500\n",
    "\n",
    "from datasets import load_dataset\n",
    "from peft import get_peft_model\n",
    "from peft import LoraConfig\n",
    "from peft import PeftConfig\n",
    "from peft import PeftModelForCausalLM\n",
    "from peft import prepare_model_for_kbit_training\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import BitsAndBytesConfig\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from transformers import default_data_collator\n",
    "from transformers import Trainer\n",
    "from transformers import TrainingArguments\n",
    "from transformers import GenerationConfig\n",
    "from trl import SFTTrainer\n",
    "import torch\n",
    "\n",
    "SENTENCE_MAX_LENGTH=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa0a9a56-4117-4808-b4ae-5dcb99194670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0806ae789fd04273af3aa50e2a0512b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/900 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = datasets.Dataset.from_json(path_or_paths='/opt/data_share/nfe_produto_1000_estruturado_anotado_train.json', split='train')\n",
    "ds = ds.select_columns(['text', 'estruturado'])\n",
    "\n",
    "def complete_prompt(row):\n",
    "    \"\"\"Add instruction to text context\"\"\"\n",
    "    text = f\"\"\"\\\n",
    "Você é um assistente que organiza itens de notas fiscais. Para cada descrição oferecida, organize os dados em formato json colocando as informações de produto, marca, quantidade e unidade de medida separados. Outras informações devem ser colocadas em um campo separado. Se os números estiverem com vírgula para separar decimais, utilizar a notação americana no json.\n",
    "\n",
    "### Descrição:\n",
    "{row['text']}\n",
    "\n",
    "### Resposta:\n",
    "{row[\"estruturado\"]}\n",
    "\n",
    "### Fim\n",
    "\"\"\"\n",
    "    return {'text_prompt': text}\n",
    "\n",
    "ds = ds.map(complete_prompt)\n",
    "ds = ds.train_test_split(test_size=0.05, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5bcc0cc-69fd-4ba2-b61c-564e792b6522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'estruturado': '{\\n'\n",
      "                \"    'produto': 'LEITE UHT INTEGRAL',\\n\"\n",
      "                \"    'marca': 'SIG LANGUIRU',\\n\"\n",
      "                \"    'quantidade': 1,\\n\"\n",
      "                \"    'unidade': 'l',\\n\"\n",
      "                \"    'observacao': ''\\n\"\n",
      "                '}',\n",
      " 'text': 'LEITE UHT INTEGRAL  SIG LANGUIRU 1LT',\n",
      " 'text_prompt': 'Você é um assistente que organiza itens de notas fiscais. '\n",
      "                'Para cada descrição oferecida, organize os dados em formato '\n",
      "                'json colocando as informações de produto, marca, quantidade e '\n",
      "                'unidade de medida separados. Outras informações devem ser '\n",
      "                'colocadas em um campo separado. Se os números estiverem com '\n",
      "                'vírgula para separar decimais, utilizar a notação americana '\n",
      "                'no json.\\n'\n",
      "                '\\n'\n",
      "                '### Descrição:\\n'\n",
      "                'LEITE UHT INTEGRAL  SIG LANGUIRU 1LT\\n'\n",
      "                '\\n'\n",
      "                '### Resposta:\\n'\n",
      "                '{\\n'\n",
      "                \"    'produto': 'LEITE UHT INTEGRAL',\\n\"\n",
      "                \"    'marca': 'SIG LANGUIRU',\\n\"\n",
      "                \"    'quantidade': 1,\\n\"\n",
      "                \"    'unidade': 'l',\\n\"\n",
      "                \"    'observacao': ''\\n\"\n",
      "                '}\\n'\n",
      "                '\\n'\n",
      "                '### Fim\\n'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(ds['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db763a7d-27fb-49e6-9b17-49ac5d58c6d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c1beaa303014899a46afe0de18da147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BASE_MODEL = '/opt/data_share/model/mistral-7b-instruct_pt_ds_v02_block_3072/checkpoint-11500/'\n",
    "SUFFIX = 'nfe-v92'\n",
    "NAME = f'llama2govbr-{SUFFIX}'\n",
    "OUTPUT = f\"/opt/data_share/model/finetunning/{NAME}\"\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    use_fast=False,\n",
    ")\n",
    "\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '<PAD>'})\n",
    "tokenizer.padding_side = 'right'\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    load_in_4bit=True,\n",
    "    quantization_config=BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_compute_dtype=torch.float16,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "    ),\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "model.resize_token_embeddings(model.config.vocab_size + 1)\n",
    "model.config.use_cache = False\n",
    "\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=128,\n",
    "    lora_alpha=256,\n",
    "    lora_dropout=0.06,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "\n",
    "ta = TrainingArguments(\n",
    "    report_to=\"none\",\n",
    "    output_dir=OUTPUT,\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    bf16=False,\n",
    "    fp16=True,\n",
    "    eval_steps=20,\n",
    "    learning_rate=3e-5,\n",
    "    weight_decay=0.001,\n",
    "\tevaluation_strategy=\"steps\",\n",
    "    save_steps=20,\n",
    "    save_total_limit=3,\n",
    "    logging_steps=10,\n",
    "    logging_first_step=True,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_bleu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b31ed1e-9fe8-4ed4-8302-9a8a8f9626f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a479e96e949b4271bee93ebbab55c1e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/855 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "514ccb8a81e44cee9bdfbb8452974125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/45 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rouge = evaluate.load('rouge')\n",
    "bleu = evaluate.load('bleu')\n",
    "\n",
    "\n",
    "def preprocess_logits_for_metrics(logits, labels):\n",
    "    if isinstance(logits, tuple):\n",
    "        logits = logits[0]\n",
    "    return logits.argmax(dim=-1)\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    \n",
    "    s_preds = preds.copy()\n",
    "    s_labels = labels.copy()\n",
    "\n",
    "    s_preds[s_preds==-100] = tokenizer.pad_token_id\n",
    "    s_labels[s_labels==-100] = tokenizer.pad_token_id\n",
    "\n",
    "    pred_str = tokenizer.batch_decode(s_preds, skip_special_tokens=True)\n",
    "    labels_str = tokenizer.batch_decode(s_labels, skip_special_tokens=True)\n",
    "    \n",
    "    labels = labels[:, 1:].reshape(-1)\n",
    "    preds = preds[:, :-1].reshape(-1)\n",
    "\n",
    "    me = {}\n",
    "    try:\n",
    "        me.update(rouge.compute(predictions=pred_str, references=labels_str))\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "        print(\"Error computing rouge\")\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        me.update(bleu.compute(predictions=pred_str, references=labels_str))\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "        print(\"Error computing bleu\")\n",
    "        pass\n",
    "\n",
    "    return me\n",
    "\n",
    "\n",
    "def tokenize(prompt):\n",
    "    result = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors='pt', \n",
    "        padding='max_length', \n",
    "        max_length=SENTENCE_MAX_LENGTH, \n",
    "        truncation=True,\n",
    "    )\n",
    "    return {\n",
    "        \"input_ids\": result[\"input_ids\"].reshape(-1),\n",
    "        \"attention_mask\": result[\"attention_mask\"].reshape(-1),\n",
    "    }\n",
    "\n",
    "\n",
    "ds = ds.map(lambda x: tokenize(x['text_prompt']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b81ac04a-de71-4fb1-8dcb-12f1798b8d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0dc62686f264ddcb39a8fe10171b729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/855 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ae406888294404fbfd22fd76e1d3c8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/45 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='106' max='106' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [106/106 03:46, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Precisions</th>\n",
       "      <th>Brevity Penalty</th>\n",
       "      <th>Length Ratio</th>\n",
       "      <th>Translation Length</th>\n",
       "      <th>Reference Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.521100</td>\n",
       "      <td>0.320930</td>\n",
       "      <td>0.903838</td>\n",
       "      <td>0.855682</td>\n",
       "      <td>0.901360</td>\n",
       "      <td>0.903186</td>\n",
       "      <td>0.838348</td>\n",
       "      <td>[0.8955532574974147, 0.8507306889352818, 0.8195995785036881, 0.791063829787234]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.009395</td>\n",
       "      <td>4835</td>\n",
       "      <td>4790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.258200</td>\n",
       "      <td>0.237159</td>\n",
       "      <td>0.938177</td>\n",
       "      <td>0.903861</td>\n",
       "      <td>0.937097</td>\n",
       "      <td>0.937558</td>\n",
       "      <td>0.901881</td>\n",
       "      <td>[0.94285116181704, 0.9146238377007607, 0.8916151056112652, 0.8698836708315382]</td>\n",
       "      <td>0.997282</td>\n",
       "      <td>0.997286</td>\n",
       "      <td>4777</td>\n",
       "      <td>4790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.244800</td>\n",
       "      <td>0.212992</td>\n",
       "      <td>0.939901</td>\n",
       "      <td>0.906228</td>\n",
       "      <td>0.938000</td>\n",
       "      <td>0.939282</td>\n",
       "      <td>0.908088</td>\n",
       "      <td>[0.9460363940598201, 0.918918918918919, 0.8974632274568323, 0.878174773999139]</td>\n",
       "      <td>0.998119</td>\n",
       "      <td>0.998121</td>\n",
       "      <td>4781</td>\n",
       "      <td>4790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.241300</td>\n",
       "      <td>0.205225</td>\n",
       "      <td>0.940796</td>\n",
       "      <td>0.907841</td>\n",
       "      <td>0.939719</td>\n",
       "      <td>0.940344</td>\n",
       "      <td>0.908703</td>\n",
       "      <td>[0.9460927705808608, 0.9185825775152922, 0.8969335604770017, 0.8776607181251344]</td>\n",
       "      <td>0.999165</td>\n",
       "      <td>0.999165</td>\n",
       "      <td>4786</td>\n",
       "      <td>4790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.237000</td>\n",
       "      <td>0.201090</td>\n",
       "      <td>0.940710</td>\n",
       "      <td>0.908814</td>\n",
       "      <td>0.939690</td>\n",
       "      <td>0.940386</td>\n",
       "      <td>0.910920</td>\n",
       "      <td>[0.9475115014638227, 0.9214692843571881, 0.9004688832054561, 0.8816440714439423]</td>\n",
       "      <td>0.998328</td>\n",
       "      <td>0.998330</td>\n",
       "      <td>4782</td>\n",
       "      <td>4790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=ta,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=ds['train'],\n",
    "    eval_dataset=ds['test'],\n",
    "    dataset_text_field='text_prompt',\n",
    "    peft_config=peft_config,\n",
    "    max_seq_length=SENTENCE_MAX_LENGTH,\n",
    "    packing=False,\n",
    "    preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model(OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b00409-7410-4787-a5f4-65eb40d54722",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb01b45b-baed-4192-863f-f2c590f03c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd23615-10d2-430d-a419-c911dba20eba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e7aa40-017f-4012-abc5-c0ec7152a916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79a0eb5-5573-4c41-89c2-2c7bbd4655f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283b9283-6bdb-4716-9aa0-634a0cbf4db3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2d2bf2-ae46-467e-a9f1-ee7023aef806",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc47ab9-c3a7-4352-a188-b0dad9e3ecbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Venv 202311_01 - Transformers 4.35",
   "language": "python",
   "name": "venv202311_01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
